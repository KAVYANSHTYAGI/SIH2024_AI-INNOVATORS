{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (1630855613.py, line 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Kavyansh Tyagi\\AppData\\Local\\Temp\\ipykernel_3508\\1630855613.py\"\u001b[1;36m, line \u001b[1;32m32\u001b[0m\n\u001b[1;33m    train_img_path = 'C:\\Users\\Kavyansh Tyagi\\OneDrive\\Desktop\\programming\\advanced computer vision\\SIH2024\\d1\\ train_img'\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "def load_and_preprocess_data(base_path, img_size=(224, 224)):\n",
    "    images = []\n",
    "    depths = []\n",
    "    labels = []\n",
    "\n",
    "    color_path = os.path.join(base_path, 'color')\n",
    "    depth_path = os.path.join(base_path, 'depth')\n",
    "    \n",
    "    for img_name in os.listdir(color_path):\n",
    "        # Load and preprocess the image\n",
    "        img = cv2.imread(os.path.join(color_path, img_name))\n",
    "        img = cv2.resize(img, img_size)\n",
    "        img = img / 255.0  # Normalize to [0, 1]\n",
    "        \n",
    "        # Load and preprocess the corresponding depth map\n",
    "        depth_name = img_name.replace('real', 'depth').replace('fake', 'depth')\n",
    "        depth = cv2.imread(os.path.join(depth_path, depth_name), cv2.IMREAD_GRAYSCALE)\n",
    "        depth = cv2.resize(depth, img_size)\n",
    "        depth = depth / 255.0  # Normalize to [0, 1]\n",
    "        \n",
    "        # Append to lists\n",
    "        images.append(img)\n",
    "        depths.append(depth)\n",
    "        \n",
    "        # Label: 0 for real, 1 for fake\n",
    "        label = 0 if 'real' in img_name else 1\n",
    "        labels.append(label)\n",
    "    \n",
    "    return np.array(images), np.array(depths), np.array(labels)\n",
    "\n",
    "# Load the training data\n",
    "train_img_path = 'C:\\Users\\Kavyansh Tyagi\\OneDrive\\Desktop\\programming\\advanced computer vision\\SIH2024\\d1\\ train_img'\n",
    "train_images, train_depths, train_labels = load_and_preprocess_data(train_img_path)\n",
    "\n",
    "# Load the testing data\n",
    "test_img_path = 'C:\\Users\\Kavyansh Tyagi\\OneDrive\\Desktop\\programming\\advanced computer vision\\SIH2024\\d1\\ test_img'\n",
    "test_images, test_depths, test_labels = load_and_preprocess_data(test_img_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\Kavyansh Tyagi\\\\OneDrive\\\\Desktop\\\\programming\\\\advanced computer vision\\\\SIH2024\\\\d1\\\\train_img\\\\train_img\\\\color'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3508\\1859411477.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m# Preprocess the images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0mcolor_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_images_and_depth_maps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;31m# Combine color and depth images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3508\\1859411477.py\u001b[0m in \u001b[0;36mpreprocess_images_and_depth_maps\u001b[1;34m(color_folder, depth_folder)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mcolor_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mdepth_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdepth_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\Kavyansh Tyagi\\\\OneDrive\\\\Desktop\\\\programming\\\\advanced computer vision\\\\SIH2024\\\\d1\\\\train_img\\\\train_img\\\\color'"
     ]
    }
   ],
   "source": [
    "# Set the base directory where 'train_img' folder is located\n",
    "base_dir = r'C:\\Users\\Kavyansh Tyagi\\OneDrive\\Desktop\\programming\\advanced computer vision\\SIH2024\\d1\\train_img'\n",
    "\n",
    "# Define the paths to 'color' and 'depth' folders\n",
    "color_folder = os.path.join(base_dir, 'train_img', 'color')\n",
    "depth_folder = os.path.join(base_dir, 'train_img', 'depth')\n",
    "\n",
    "# Function to preprocess images and depth maps\n",
    "def preprocess_images_and_depth_maps(color_folder, depth_folder):\n",
    "    color_images = []\n",
    "    depth_images = []\n",
    "    labels = []\n",
    "\n",
    "    for filename in os.listdir(color_folder):\n",
    "        color_path = os.path.join(color_folder, filename)\n",
    "        depth_path = os.path.join(depth_folder, filename)\n",
    "\n",
    "        if os.path.exists(color_path) and os.path.exists(depth_path):\n",
    "            # Read and preprocess the color image\n",
    "            color_image = cv2.imread(color_path)\n",
    "            color_image = cv2.resize(color_image, (224, 224))\n",
    "            color_image = color_image / 255.0  # Normalize to [0, 1]\n",
    "            color_images.append(color_image)\n",
    "\n",
    "            # Read and preprocess the depth image\n",
    "            depth_image = cv2.imread(depth_path, cv2.IMREAD_GRAYSCALE)\n",
    "            depth_image = cv2.resize(depth_image, (224, 224))\n",
    "            depth_image = depth_image / 255.0  # Normalize to [0, 1]\n",
    "            depth_images.append(depth_image)\n",
    "\n",
    "            # Determine label based on filename (assuming filenames contain 'real' or 'fake')\n",
    "            if 'real' in filename:\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    color_images = np.array(color_images)\n",
    "    depth_images = np.expand_dims(np.array(depth_images), axis=-1)  # Expand dims for depth\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return color_images, depth_images, labels\n",
    "\n",
    "# Preprocess the images\n",
    "color_images, depth_images, labels = preprocess_images_and_depth_maps(color_folder, depth_folder)\n",
    "\n",
    "# Combine color and depth images\n",
    "combined_images = np.concatenate([color_images, depth_images], axis=-1)\n",
    "\n",
    "# Create TensorFlow dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((combined_images, labels))\n",
    "dataset = dataset.shuffle(buffer_size=1000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Sample Output\n",
    "for images, labels in dataset.take(1):\n",
    "    print(images.shape)\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for training set\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.01,\n",
    "    zoom_range=[0.9, 1.25],\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='reflect'\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Convolutional layers\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Fully connected layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    \n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    \n",
    "    model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "input_shape = (112, 112, 4)  # 3 color channels + 1 depth channel\n",
    "model = create_model(input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on the training data\n",
    "model.fit(train_generator, epochs=10, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('face_spoofing_detector_tf.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
