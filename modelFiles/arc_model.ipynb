{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, LSTM, Dense, Flatten, Reshape\n",
    "from tensorflow.keras.models import Model, Sequential \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define paths\n",
    "data_dir = '/path/to/casia-fasd'  # Replace with your dataset path\n",
    "real_label = 0\n",
    "spoof_label = 1\n",
    "\n",
    "# Function to load images\n",
    "def load_images_from_folder(folder, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (224, 224))  # Resize to MobileNetV2 expected input size\n",
    "            img = img / 255.0  # Normalize the image\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load real and spoof images\n",
    "real_images, real_labels = load_images_from_folder(os.path.join(data_dir, 'real'), real_label)\n",
    "spoof_images, spoof_labels = load_images_from_folder(os.path.join(data_dir, 'spoof'), spoof_label)\n",
    "\n",
    "# Combine real and spoof images\n",
    "X = np.concatenate((real_images, spoof_images), axis=0)\n",
    "y = np.concatenate((real_labels, spoof_labels), axis=0)\n",
    "\n",
    "# One-hot encode labels\n",
    "y = to_categorical(y, num_classes=2)\n",
    "\n",
    "# Split dataset into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Convert to TensorFlow Dataset for efficient loading and training\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(32).shuffle(buffer_size=1024)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(32)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(32)\n",
    "\n",
    "# Optionally, save datasets\n",
    "np.savez('/path/to/save/casia_train.npz', X_train=X_train, y_train=y_train)\n",
    "np.savez('/path/to/save/casia_val.npz', X_val=X_val, y_val=y_val)\n",
    "np.savez('/path/to/save/casia_test.npz', X_test=X_test, y_test=y_test)\n",
    "\n",
    "# Now the datasets are ready for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_feature_extractor(input_shape):\n",
    "    base_model = tf.keras.applications.MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "    base_model.trainable = False  # Freezing the base model for efficiency\n",
    "    x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    return models.Model(inputs=base_model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_temporal_analysis(x, lstm_units=64):\n",
    "    # Reshape to make sure it's in the right shape for LSTM\n",
    "    x = layers.Reshape((-1, x.shape[-1]))(x)\n",
    "    \n",
    "    # LSTM for detecting temporal patterns\n",
    "    x = layers.LSTM(lstm_units, return_sequences=True)(x)\n",
    "    x = layers.LSTM(lstm_units, return_sequences=True)(x)\n",
    "    \n",
    "    # Self-Attention to capture repetitive patterns\n",
    "    attention = layers.MultiHeadAttention(num_heads=4, key_dim=lstm_units)(x, x)\n",
    "    x = layers.Add()([x, attention])\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiny_transformer_block(x, d_model, num_heads, dff, training):\n",
    "    attn_output = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(x, x)\n",
    "    attn_output = layers.Dropout(0.1)(attn_output, training=training)\n",
    "    out1 = layers.LayerNormalization(epsilon=1e-6)(x + attn_output)\n",
    "\n",
    "    ffn_output = layers.Dense(dff, activation='relu')(out1)\n",
    "    ffn_output = layers.Dense(d_model)(ffn_output)\n",
    "    ffn_output = layers.Dropout(0.1)(ffn_output, training=training)\n",
    "\n",
    "    return layers.LayerNormalization(epsilon=1e-6)(out1 + ffn_output)\n",
    "\n",
    "def ensemble_adapters(x, num_adapters, d_model, bottleneck_dim):\n",
    "    adapter_outputs = []\n",
    "    for _ in range(num_adapters):\n",
    "        adapter = layers.Dense(bottleneck_dim, activation='gelu')(x)\n",
    "        adapter = layers.Dense(d_model)(adapter)\n",
    "        adapter_outputs.append(adapter)\n",
    "\n",
    "    adapter_outputs = tf.stack(adapter_outputs, axis=0)\n",
    "    adapter_outputs = tf.reduce_mean(adapter_outputs, axis=0)\n",
    "    \n",
    "    return x + adapter_outputs\n",
    "\n",
    "def feature_wise_transformation(x, d_model):\n",
    "    scale = tf.Variable(initial_value=tf.ones((d_model,)), trainable=True)\n",
    "    shift = tf.Variable(initial_value=tf.zeros((d_model,)), trainable=True)\n",
    "    return x * scale + shift\n",
    "\n",
    "def adaptive_transformer_block(x, d_model, num_heads, dff, num_adapters, bottleneck_dim, training):\n",
    "    x = tiny_transformer_block(x, d_model, num_heads, dff, training)\n",
    "    x = ensemble_adapters(x, num_adapters, d_model, bottleneck_dim)\n",
    "    return feature_wise_transformation(x, d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_conditional_domain_discriminator(x, num_domains, d_model):\n",
    "    x = layers.Dense(d_model, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    domain_pred = layers.Dense(num_domains, activation='softmax', name='domain_output')(x)\n",
    "    return domain_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_combined_model(input_shape, d_model=64, num_heads=4, dff=128, num_blocks=4, num_adapters=2, bottleneck_dim=32, lstm_units=64, num_domains=2):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # ResNet Feature Extraction\n",
    "    resnet_model = resnet_feature_extractor(input_shape=input_shape)\n",
    "    x = resnet_model(inputs)\n",
    "\n",
    "    # LSTM for Temporal Analysis and Repetitive Pattern Detection\n",
    "    x = lstm_temporal_analysis(x, lstm_units=lstm_units)\n",
    "\n",
    "    # Reshape for Transformer input\n",
    "    x = layers.Reshape((1, -1))(x)  # Adjust based on expected transformer input\n",
    "\n",
    "    # Adaptive Transformer Blocks\n",
    "    for _ in range(num_blocks):\n",
    "        x = adaptive_transformer_block(x, d_model, num_heads, dff, num_adapters, bottleneck_dim, training=True)\n",
    "\n",
    "    # Global Pooling and Feature Extraction\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "    # Class-Conditional Domain Discriminator\n",
    "    domain_pred = class_conditional_domain_discriminator(x, num_domains, d_model)\n",
    "    \n",
    "    # Final Classification (Real vs Spoof)\n",
    "    spoof_pred = layers.Dense(1, activation='sigmoid', name='spoof_output')(x)\n",
    "\n",
    "    return models.Model(inputs=inputs, outputs=[spoof_pred, domain_pred])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(64,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_3), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(64,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_1), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(64,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_7), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(64,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_2), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(64,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_11), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(64,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_3), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(64,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_15), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(64,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "Epoch 1/10\n",
      "7/7 [==============================] - 13s 111ms/step - loss: 1.7886 - spoof_output_loss: 0.8909 - domain_output_loss: 0.8976 - spoof_output_accuracy: 0.4600 - domain_output_accuracy: 0.5300\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 1s 114ms/step - loss: 1.7269 - spoof_output_loss: 0.7379 - domain_output_loss: 0.9890 - spoof_output_accuracy: 0.5600 - domain_output_accuracy: 0.4600\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 1s 114ms/step - loss: 1.5862 - spoof_output_loss: 0.8049 - domain_output_loss: 0.7814 - spoof_output_accuracy: 0.5400 - domain_output_accuracy: 0.6000\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 1.5054 - spoof_output_loss: 0.7487 - domain_output_loss: 0.7567 - spoof_output_accuracy: 0.4500 - domain_output_accuracy: 0.4900\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 1s 122ms/step - loss: 1.4015 - spoof_output_loss: 0.7041 - domain_output_loss: 0.6974 - spoof_output_accuracy: 0.5400 - domain_output_accuracy: 0.5500\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 1.4054 - spoof_output_loss: 0.7143 - domain_output_loss: 0.6911 - spoof_output_accuracy: 0.4900 - domain_output_accuracy: 0.5400\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 1s 126ms/step - loss: 1.4122 - spoof_output_loss: 0.7261 - domain_output_loss: 0.6861 - spoof_output_accuracy: 0.3700 - domain_output_accuracy: 0.5700\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 1s 127ms/step - loss: 1.4505 - spoof_output_loss: 0.7499 - domain_output_loss: 0.7006 - spoof_output_accuracy: 0.5300 - domain_output_accuracy: 0.5200\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 1s 123ms/step - loss: 1.4081 - spoof_output_loss: 0.7042 - domain_output_loss: 0.7039 - spoof_output_accuracy: 0.5200 - domain_output_accuracy: 0.5500\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 1.4130 - spoof_output_loss: 0.7108 - domain_output_loss: 0.7022 - spoof_output_accuracy: 0.4300 - domain_output_accuracy: 0.5400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1905b26f408>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "input_shape = (224, 224, 3)  # Example input shape for an image\n",
    "\n",
    "model = build_combined_model(input_shape=input_shape)\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss={'spoof_output': 'binary_crossentropy', 'domain_output': 'categorical_crossentropy'}, \n",
    "              metrics={'spoof_output': 'accuracy', 'domain_output': 'accuracy'})\n",
    "\n",
    "# Example data\n",
    "X_train = np.random.random((100, 224, 224, 3))\n",
    "y_train_spoof = np.random.randint(2, size=(100, 1))\n",
    "y_train_domain = tf.keras.utils.to_categorical(np.random.randint(2, size=(100, 1)), num_classes=2)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, {'spoof_output': y_train_spoof, 'domain_output': y_train_domain}, epochs=10, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_model_optimization'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12752\\1224189889.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_model_optimization\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtfmot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Define a pruning schedule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(\n\u001b[0;32m      5\u001b[0m     \u001b[0minitial_sparsity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_sparsity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbegin_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_model_optimization'"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "# Define a pruning schedule\n",
    "pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(\n",
    "    initial_sparsity=0.0, final_sparsity=0.5, begin_step=2000, end_step=10000\n",
    ")\n",
    "\n",
    "# Apply pruning\n",
    "pruned_model = tfmot.sparsity.keras.prune_low_magnitude(\n",
    "    model, pruning_schedule=pruning_schedule\n",
    ")\n",
    "\n",
    "# Compile the pruned model\n",
    "pruned_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fine-tune the pruned model\n",
    "callbacks = [tfmot.sparsity.keras.UpdatePruningStep()]\n",
    "pruned_model.fit(x_train, y_train, epochs=3, validation_split=0.1, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip the pruning wrappers\n",
    "final_model = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
    "\n",
    "# Save the model\n",
    "final_model.save('pruned_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n",
    "\n",
    "# Enable full integer quantization\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Convert the model\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the quantized model\n",
    "with open('quantized_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
